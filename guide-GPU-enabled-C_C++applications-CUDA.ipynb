{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXATwZ8VxZG7"
   },
   "source": [
    "# Fundamentals of Accelerated Computing with CUDA C/C++\n",
    "\n",
    " Murilo Boratto$^1$\n",
    "\n",
    "$^1$ SENAI CIMATEC <br />\n",
    "     &nbsp;&nbsp;&nbsp; Supercomputing Center<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyB9gzUjSGKc"
   },
   "source": [
    "### Enabled GPU in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTFR6-5Ja64x"
   },
   "source": [
    "**Go to Menu > Runtime > Change runtime > V100 GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynQEmQTgW_hs"
   },
   "source": [
    "### Instalation the APIs OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GOdF9A-XDcf"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install libomp-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pfFUL-maxh4"
   },
   "source": [
    "### Check if GPU is running or not, run the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cIWeteLFbMdM",
    "outputId": "945fb610-ad3a-474f-ab12-1669344bb071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 19 17:41:07 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:60:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    45W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    45W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqclQCVqjE3u"
   },
   "source": [
    "### Check if nvcc compiler is capable of using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sFT0dpBBjNs1",
    "outputId": "35132fb0-9247-4acf-9d62-a758cab2db8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqGTiMLEbEdx"
   },
   "source": [
    "## `Matrix Multiply Code Portability and Optimization using CUDA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0goqSor0VbID"
   },
   "source": [
    "### Sequential Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wH2wRXo9VSgH",
    "outputId": "1efe8728-2920-4fd9-8025-d6c275322a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void kernel(int *A, int *B, int size)\n",
    "{\n",
    " int i, j, k;\n",
    "\n",
    " for(i = 0; i < size; i++)\n",
    "  for(j = 0; j < size; j++)\n",
    "    for(k = 0; k < size; k++)\n",
    "       B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "}\n",
    "\n",
    "void initializeMatrix(int *matrix, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "      matrix[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *matrix, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "  {\n",
    "    for(j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", matrix[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main (int argc, char **argv)\n",
    "{\n",
    " int size = atoi(argv[1]);\n",
    " int i, j, k;\n",
    " double t1, t2;\n",
    "\n",
    " int  *A = (int *) malloc (sizeof(int) * size * size);\n",
    " int  *B = (int *) malloc (sizeof(int) * size * size);\n",
    "\n",
    " initializeMatrix(A, size);\n",
    " initializeMatrix(B, size);\n",
    "\n",
    " t1 = omp_get_wtime();\n",
    "   kernel(A, B, size);\n",
    " t2 = omp_get_wtime();\n",
    "\n",
    " printf(\"%d\\t%f\\n\", size, t2-t1);\n",
    "\n",
    " //printMatrix(A,size);\n",
    " //printMatrix(B,size);\n",
    "\n",
    " // Free all our allocated memory\n",
    " free(A);\n",
    " free(B);\n",
    "\n",
    " return 0;\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ihrvZEJ0Wd5P"
   },
   "outputs": [],
   "source": [
    "!gcc mm.c -o mm -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bwhOuSG9Wd_P",
    "outputId": "3691414d-8247-4479-929c-b209ee33d372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t4.664137\n"
     ]
    }
   ],
   "source": [
    "!./mm 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "823d_hqHqTdN"
   },
   "source": [
    "### `CUDA Thread Hierarchy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tn_S8PRHbcnQ",
    "outputId": "688a243d-44b8-4012-b7ac-aa0f12b79b7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"center\">\n",
       "<iframe src=\"https://docs.google.com/presentation/d/1J_GF6XACL0-Dk1BtJCeWiHwJCFcM_Hkx/edit?usp=share_link&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
       "\n",
       "</iframe></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<div align=\"center\">\n",
    "<iframe src=\"https://docs.google.com/presentation/d/1J_GF6XACL0-Dk1BtJCeWiHwJCFcM_Hkx/edit?usp=share_link&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
    "\n",
    "</iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2hTtR30ikC5N",
    "outputId": "c4bd7817-9ccc-4de8-9ce6-76b31bcfa547",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm.cu\n",
    "#include <cuda.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "__global__ void kernel(int *A, int *B, int size)\n",
    "{\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int k;\n",
    "\n",
    "  if((i < size) && (j < size))\n",
    "    for(k = 0; k < size; k++)\n",
    "       B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "\n",
    "}\n",
    "\n",
    "void initializeMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "       A[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "  {\n",
    "    for(j = 0; j < size; j++)\n",
    "       printf(\"%d\\t\", A[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int size = atoi(argv[1]);\n",
    "  int blockSize = atoi(argv[2]);\n",
    "  double t1, t2;\n",
    "\n",
    "  // Memory Allocation in the Host\n",
    "  int  *A = (int *) malloc (sizeof(int) * size * size);\n",
    "  int  *B = (int *) malloc (sizeof(int) * size * size);\n",
    " \n",
    "  initializeMatrix(A, size);\n",
    "  initializeMatrix(B, size);\n",
    "\n",
    "  t1 = omp_get_wtime();\n",
    "  \n",
    "  // Memory Allocation in the Device\n",
    "  int *d_A, *d_B;\n",
    "  cudaMalloc((void **) &d_A, size * size * sizeof(int));\n",
    "  cudaMalloc((void **) &d_B, size * size * sizeof(int));\n",
    " \n",
    "  // Copy of data from host to device\n",
    "  cudaMemcpy( d_A, A, size * size * sizeof(int), cudaMemcpyHostToDevice);\n",
    "  cudaMemcpy( d_B, B, size * size * sizeof(int), cudaMemcpyHostToDevice);\n",
    " \n",
    "  // 2D Computational Grid\n",
    "  dim3 dimGrid((int) ceil( (int) size / (int) blockSize ), (int) ceil( (int) size / (int) blockSize ));\n",
    "  dim3 dimBlock( blockSize, blockSize);\n",
    "\n",
    "       kernel<<<dimGrid, dimBlock>>>(A, B, size);\n",
    "\n",
    "  // Copy of data from device to host\n",
    "  cudaMemcpy( B, d_B, size * size * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  t2 = omp_get_wtime();\n",
    "\n",
    "  printf(\"%d\\t%f\\n\", size, t2-t1);\n",
    "\n",
    " //printMatrix(B, size);\n",
    " \n",
    " // Memory Allocation in the Device\n",
    " cudaFree(d_A);\n",
    " cudaFree(d_B);\n",
    " \n",
    " // Memory Allocation in the Host\n",
    " free(A);\n",
    " free(B);\n",
    "\n",
    " return 0;\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FTVBh76aSywY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 mm.cu -o mm -Xcompiler -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TCAWmPrRYc6W",
    "outputId": "e1e1faa3-c42b-4a23-abf7-0d4ee58d8ef4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.191586\n"
     ]
    }
   ],
   "source": [
    "!./mm 1000 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edaoNwRFeJK9"
   },
   "source": [
    "### `Grid-Stride Loops`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ymjx2tcvoTYF",
    "outputId": "0eabe683-f0f0-44bd-e470-96349fd2c707"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"center\">\n",
       "<iframe src=\"https://docs.google.com/presentation/d/1tRO-HwqCfv8imhDO4S_8yAv8wEcJVttZ/edit?usp=sharing&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
       "\n",
       "</iframe></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<div align=\"center\">\n",
    "<iframe src=\"https://docs.google.com/presentation/d/1tRO-HwqCfv8imhDO4S_8yAv8wEcJVttZ/edit?usp=sharing&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
    "\n",
    "</iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MZpA7sUlLVgZ",
    "outputId": "20102f6c-5bf6-4dcc-d89e-04ebc13e27f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm-gridStrideLoop.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm-gridStrideLoop.cu\n",
    "#include <cuda.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "__global__ void kernel(int *A, int *B, int size)\n",
    "{\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int k;\n",
    "\n",
    "  if((i < size) && (j < size))\n",
    "    for(k = 0; k < size; k++)\n",
    "       B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "\n",
    "}\n",
    "\n",
    "__global__ void kernelGridStrideLoop(int *A, int *B, int size)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int stride = gridDim.x * blockDim.x;\n",
    "  int i, j, k;\n",
    "\n",
    "  for(i = idx; i < size; i += stride)\n",
    "    for(j = idy; j < size; j += stride)\n",
    "    {\n",
    "       for(k = 0; k < size; k++)\n",
    "            B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "void initializeMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "      A[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "  {\n",
    "    for(j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", A[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int size = atoi(argv[1]);\n",
    "  int blockSize = atoi(argv[2]);\n",
    "  double t1, t2;\n",
    "\n",
    "  // Memory Allocation in the Host\n",
    "  int  *A = (int *) malloc (sizeof(int) * size * size);\n",
    "  int  *B = (int *) malloc (sizeof(int) * size * size);\n",
    " \n",
    "  initializeMatrix(A, size);\n",
    "  initializeMatrix(B, size);\n",
    "\n",
    "  t1 = omp_get_wtime();\n",
    "    \n",
    "  // Memory Allocation in the Device\n",
    "  int *d_A, *d_B;\n",
    "  cudaMalloc((void **) &d_A, size * size * sizeof(int));\n",
    "  cudaMalloc((void **) &d_B, size * size * sizeof(int));\n",
    "  \n",
    "  // Copy of data from host to device\n",
    "  cudaMemcpy( d_A, A, size * size * sizeof(int), cudaMemcpyHostToDevice );\n",
    "  cudaMemcpy( d_B, B, size * size * sizeof(int), cudaMemcpyHostToDevice );\n",
    "  \n",
    "  // 2D Computational Grid\n",
    "  dim3 dimGrid( (int) ceil( (int) size / (int) blockSize ), (int) ceil( (int) size / (int) blockSize ) );\n",
    "  dim3 dimBlock( blockSize, blockSize);\n",
    "\n",
    "            kernelGridStrideLoop<<<dimGrid, dimBlock>>>(A, B, size);\n",
    "\n",
    "  // Copy of data from device to host\n",
    "  cudaMemcpy( B, d_B, size * size * sizeof(int), cudaMemcpyDeviceToHost );\n",
    "\n",
    "  t2 = omp_get_wtime();\n",
    "\n",
    "  printf(\"%d\\t%f\\n\", size, t2-t1);\n",
    "\n",
    " //printMatrix(A, size);\n",
    " //printMatrix(B, size);\n",
    "\n",
    " // Memory Allocation in the Device\n",
    " cudaFree(d_A);\n",
    " cudaFree(d_B);\n",
    " \n",
    " // Memory Allocation in the Host\n",
    " free(A);\n",
    " free(B);\n",
    " \n",
    " return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "W6r-gx0_Ld2G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 mm-gridStrideLoop.cu -o mm-gridStrideLoop -Xcompiler -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RL9LL2OmLhvM",
    "outputId": "e04f3864-3e98-475d-b168-8d2b5da19fbc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.190511\n"
     ]
    }
   ],
   "source": [
    "!./mm-gridStrideLoop 1000 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFTvpmQBeJK-"
   },
   "source": [
    "### `Unified Memory (cudaMallocManaged)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "H3ThCItfoTYH",
    "outputId": "9076f4a7-554d-4af0-b062-be5ef926e55f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"center\">\n",
       "<iframe src=\"https://docs.google.com/presentation/d/1ZgEGCivfxKS6DDHsq1-3-k4YELQQknZ0/edit?usp=share_link&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
       "\n",
       "</iframe></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<div align=\"center\">\n",
    "<iframe src=\"https://docs.google.com/presentation/d/1ZgEGCivfxKS6DDHsq1-3-k4YELQQknZ0/edit?usp=share_link&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
    "\n",
    "</iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1B3TRZ5CeJK_",
    "outputId": "c04613a2-22e6-481c-99de-d42fab5e89a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm-cudaMallocManaged.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm-cudaMallocManaged.cu\n",
    "#include <cuda.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "__global__ void kernel(int *A, int *B, int size)\n",
    "{\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int k;\n",
    "\n",
    "  if((i < size) && (j < size))\n",
    "     for(k = 0; k < size; k++)\n",
    "        B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "\n",
    "}\n",
    "\n",
    "__global__ void kernelGridStrideLoop(int *A, int *B, int size)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int stride = gridDim.x * blockDim.x;\n",
    "  int i, j, k;\n",
    "\n",
    "  for(i = idx; i < size; i += stride)\n",
    "    for(j = idy; j < size; j += stride)\n",
    "    {\n",
    "       for(k = 0; k < size; k++)\n",
    "            B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "void initializeMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "      A[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "  {\n",
    "    for(j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", A[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{ \n",
    " int size = atoi(argv[1]);\n",
    " int blockSize = atoi(argv[2]); ;\n",
    " double t1, t2;\n",
    " int *A,  *B;\n",
    "\n",
    " t1 = omp_get_wtime();\n",
    "\n",
    " cudaMallocManaged(&A, sizeof(int) * size * size);\n",
    " cudaMallocManaged(&B, sizeof(int) * size * size);\n",
    "\n",
    " initializeMatrix(A, size);\n",
    " initializeMatrix(B, size);\n",
    "\n",
    " dim3 dimGrid( (int) ceil( (int) size / (int) blockSize ), (int) ceil( (int) size / (int) blockSize ) );\n",
    " dim3 dimBlock( blockSize, blockSize);\n",
    "\n",
    "      kernelGridStrideLoop<<<dimGrid, dimBlock>>>(A, B, size);\n",
    "      cudaDeviceSynchronize();\n",
    "\n",
    " t2 = omp_get_wtime();\n",
    "\n",
    "printf(\"%d\\t%f\\n\", size, (t2-t1));\n",
    "\n",
    "//printMatrix(A, size);\n",
    "//printMatrix(B, size);\n",
    "\n",
    "// Free all our allocated memory\n",
    "cudaFree(A);\n",
    "cudaFree(B);\n",
    "\n",
    "return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "inrnf5OpeJK_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvcc mm-cudaMallocManaged.cu -o mm-cudaMallocManaged -Xcompiler -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qfwoEnWKeJK_",
    "outputId": "cc3a2487-410e-46ec-f517-9cd3203619d7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.222651\n"
     ]
    }
   ],
   "source": [
    "!./mm-cudaMallocManaged 1000 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYP1lJrZok32"
   },
   "source": [
    "#### `Streaming Multiprocessors (SMs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JLa0RujAoTYI",
    "outputId": "4b8e4b5b-f784-4383-9419-e2b8f01a97ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"center\">\n",
       "<iframe src=\"https://docs.google.com/presentation/d/18z3x55kxCCjGZ3LVKOtSN5q8qXe4swFL/edit?usp=sharing&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
       "\n",
       "</iframe></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<div align=\"center\">\n",
    "<iframe src=\"https://docs.google.com/presentation/d/18z3x55kxCCjGZ3LVKOtSN5q8qXe4swFL/edit?usp=sharing&ouid=117965215426975519312&rtpof=true&sd=true\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n",
    "\n",
    "</iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IH8IX1MAok33",
    "outputId": "7f5b7cd6-e269-4194-bd8a-8a26cd9ea90c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm-streamingMultiprocessors.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm-streamingMultiprocessors.cu\n",
    "#include <cuda.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "__global__ void kernelGridStrideLoop(int *A, int *B, int size)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "  int stride = gridDim.x * blockDim.x;\n",
    "  int i, j, k;\n",
    "\n",
    "  for(i = idx; i < size; i += stride)\n",
    "    for(j = idy; j < size; j += stride)\n",
    "    {\n",
    "       for(k = 0; k < size; k++)\n",
    "         B[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "void initializeMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "      A[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *A, int size)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < size; i++)\n",
    "  {\n",
    "    for(j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", A[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main (int argc, char **argv)\n",
    "{\n",
    " int size = atoi(argv[1]);\n",
    " int sizeblock = atoi(argv[2]); ;\n",
    " double t1, t2;\n",
    " int *A,  *B;\n",
    "\n",
    " t1 = omp_get_wtime();\n",
    "\n",
    " cudaMallocManaged(&A, sizeof(int) * size * size);\n",
    " cudaMallocManaged(&B, sizeof(int) * size * size);\n",
    "\n",
    " initializeMatrix(A, size);\n",
    " initializeMatrix(B, size);\n",
    "\n",
    " int deviceId, numberOfSMs;\n",
    " cudaGetDevice(&deviceId);\n",
    " cudaDeviceGetAttribute(&numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);\n",
    "\n",
    " int NUMBER_OF_BLOCKS = numberOfSMs * 32;\n",
    " int NUMBER_OF_THREADS = 1024;\n",
    "\n",
    "      kernelGridStrideLoop<<< NUMBER_OF_BLOCKS, NUMBER_OF_THREADS>>>(A, B, size);\n",
    "      cudaDeviceSynchronize();\n",
    "\n",
    " t2 = omp_get_wtime();\n",
    "\n",
    " printf(\"%d\\t%f\\n\", size, t2-t1);\n",
    "\n",
    "//printMatrix(B, size);\n",
    "\n",
    "// Free all our allocated memory\n",
    " cudaFree(A);\n",
    " cudaFree(B);\n",
    "\n",
    " return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "jXKV9XKZok33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvcc mm-streamingMultiprocessors.cu -o mm-streamingMultiprocessors -Xcompiler -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "JAg-VF-qok33",
    "outputId": "fd8cb7b5-4dc3-4a51-8eab-53367cb638fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.226932\n"
     ]
    }
   ],
   "source": [
    "!./mm-streamingMultiprocessors 1000 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Profilling GPU core`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPU has many units working in parallel, and it is common for it to be bound by different units at different frame sequences. Due to the nature of this behavior, it is beneficial to identify where the GPU cost is going when searching for bottlenecks and to understand what a GPU bottleneck is. Some applications help developers identify bottlenecks, which is useful when optimizing performance, following some NVIDIA profilling tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vector-add.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector-add.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "void initWith(float num, float *a, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; ++i)\n",
    "    a[i] = num;\n",
    "  \n",
    "}\n",
    "\n",
    "__global__ void addVectorsInto(float *result, float *a, float *b, int N)\n",
    "{\n",
    "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "\n",
    "  for(int i = index; i < N; i += stride)\n",
    "    result[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "void checkElementsAre(float target, float *vector, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    if(vector[i] != target)\n",
    "    {\n",
    "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
    "      exit(1);\n",
    "    }\n",
    "  }\n",
    "  printf(\"Success! All values calculated correctly.\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  const int N = 2<<24;\n",
    "  size_t size = N * sizeof(float);\n",
    "\n",
    "  float *a;\n",
    "  float *b;\n",
    "  float *c;\n",
    "\n",
    "  cudaMallocManaged(&a, size);\n",
    "  cudaMallocManaged(&b, size);\n",
    "  cudaMallocManaged(&c, size);\n",
    "\n",
    "  initWith(3, a, N);\n",
    "  initWith(4, b, N);\n",
    "  initWith(0, c, N);\n",
    "\n",
    "  size_t threadsPerBlock;\n",
    "  size_t numberOfBlocks;\n",
    "\n",
    "  int deviceId;\n",
    "  cudaGetDevice(&deviceId);\n",
    "\n",
    "  cudaDeviceProp props;\n",
    "  cudaGetDeviceProperties(&props, deviceId);\n",
    "  int multiProcessorCount = props.multiProcessorCount;\n",
    "  threadsPerBlock = 1024;\n",
    "  numberOfBlocks = 32 * multiProcessorCount;\n",
    "  \n",
    "  cudaError_t addVectorsErr;\n",
    "  cudaError_t asyncErr;\n",
    "\n",
    "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
    "\n",
    "  addVectorsErr = cudaGetLastError();\n",
    "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
    "\n",
    "  asyncErr = cudaDeviceSynchronize();\n",
    "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
    "\n",
    "  checkElementsAre(7, c, N);\n",
    "\n",
    "  // Free all our allocated memory  \n",
    "  cudaFree(a);\n",
    "  cudaFree(b);\n",
    "  cudaFree(c);\n",
    "    \n",
    "  return 0;      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vector-add.cu -o vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ NSYS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NVIDIA Nsight Systems` (nsys) is a system-wide performance analysis tool designed to visualize an application’s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `nsys profile` will generate a `qdrep` report file which can be used in a variety of manners. We use the `--stats=true` flag here to indicate we would like summary statistics printed. There is quite a lot of information printed:\n",
    "\n",
    "- Profile configuration details\n",
    "- Report file(s) generation details\n",
    "- **CUDA API Statistics**\n",
    "- **CUDA Kernel Statistics**\n",
    "- **CUDA Memory Operation Statistics (time and size)**\n",
    "- OS Runtime API Statistics\n",
    "\n",
    "In this lab you will primarily be using the nsys im command line. In the next, you will be using the generated report files to give to the Nsight Systems GUI for visual profilling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! All values calculated correctly.\n",
      "Generating '/tmp/nsys-report-2f5d.qdstrm'\n",
      "[1/8] [========================100%] report4.nsys-rep\n",
      "[2/8] [========================100%] report4.sqlite\n",
      "[3/8] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /home/murilo/report4.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/8] Executing 'osrtsum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)        Name     \n",
      " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  --------------\n",
      "     81,0    1.075.978.685         66  16.302.707,0  10.146.761,0     1.834  100.438.884  24.925.543,0  poll          \n",
      "     10,0      137.811.825         59   2.335.793,0   2.124.556,0    16.228   21.238.331   3.502.350,0  sem_timedwait \n",
      "      5,0       77.532.986      1.032      75.128,0      19.884,0     1.045   26.221.327     832.433,0  ioctl         \n",
      "      2,0       26.460.687         33     801.839,0       5.057,0     1.119    9.770.497   2.547.205,0  mmap          \n",
      "      0,0        2.203.631         46      47.905,0       4.650,0     2.562    1.661.363     243.806,0  mmap64        \n",
      "      0,0        1.185.584          4     296.396,0     301.482,0    76.790      505.829     237.638,0  pthread_create\n",
      "      0,0          949.313         51      18.614,0       4.069,0     1.363      518.866      77.226,0  fopen         \n",
      "      0,0          415.874         87       4.780,0       4.138,0     2.082       18.237       2.332,0  open64        \n",
      "      0,0          332.953         45       7.399,0       3.566,0     1.673       64.126      13.101,0  fclose        \n",
      "      0,0          192.815         11      17.528,0       2.598,0     1.528       76.587      29.577,0  munmap        \n",
      "      0,0          127.606          3      42.535,0      54.116,0     1.074       72.416      37.054,0  fcntl         \n",
      "      0,0          109.449          3      36.483,0      15.130,0     7.509       86.810      43.750,0  fread         \n",
      "      0,0           42.974          1      42.974,0      42.974,0    42.974       42.974           0,0  fgets         \n",
      "      0,0           35.139          6       5.856,0       4.942,0     2.406        9.816       3.314,0  open          \n",
      "      0,0           32.432         12       2.702,0       2.369,0     1.481        4.649         966,0  write         \n",
      "      0,0           16.700         11       1.518,0       1.171,0     1.019        3.559         821,0  read          \n",
      "      0,0            9.308          2       4.654,0       4.654,0     2.890        6.418       2.494,0  socket        \n",
      "      0,0            8.344          4       2.086,0       2.136,0     1.779        2.293         244,0  mprotect      \n",
      "      0,0            8.019          1       8.019,0       8.019,0     8.019        8.019           0,0  connect       \n",
      "      0,0            4.210          1       4.210,0       4.210,0     4.210        4.210           0,0  pipe2         \n",
      "      0,0            1.547          1       1.547,0       1.547,0     1.547        1.547           0,0  bind          \n",
      "\n",
      "[5/8] Executing 'cudaapisum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)            Name         \n",
      " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  ----------------------\n",
      "     51,0      141.210.218          3   47.070.072,0       37.411,0       15.427  141.157.380  81.481.999,0  cudaMallocManaged     \n",
      "     39,0      108.347.156          1  108.347.156,0  108.347.156,0  108.347.156  108.347.156           0,0  cudaDeviceSynchronize \n",
      "      9,0       26.445.300          3    8.815.100,0    8.444.199,0    8.186.799    9.814.302     874.852,0  cudaFree              \n",
      "      0,0           72.971          1       72.971,0       72.971,0       72.971       72.971           0,0  cudaLaunchKernel      \n",
      "      0,0            2.985          1        2.985,0        2.985,0        2.985        2.985           0,0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'gpukernsum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)     GridXYZ         BlockXYZ                          Name                     \n",
      " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  --------------  --------------  ----------------------------------------------\n",
      "    100,0      108.347.721          1  108.347.721,0  108.347.721,0  108.347.721  108.347.721          0,0  2560    1    1  1024    1    1  addVectorsInto(float *, float *, float *, int)\n",
      "\n",
      "[7/8] Executing 'gpumemtimesum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count   Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
      " --------  ---------------  ------  --------  --------  --------  --------  -----------  ---------------------------------\n",
      "     86,0       71.632.877  12.715   5.633,0   3.615,0     2.815    88.672      9.373,0  [CUDA Unified Memory memcpy HtoD]\n",
      "     13,0       11.319.937     768  14.739,0   4.191,0     1.918    81.504     22.753,0  [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "[8/8] Executing 'gpumemsizesum' stats report\n",
      "\n",
      " Total (MB)  Count   Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
      " ----------  ------  --------  --------  --------  --------  -----------  ---------------------------------\n",
      " 402,653     12.715  0,032     0,008     0,004     1,044     0,114        [CUDA Unified Memory memcpy HtoD]\n",
      " 134,218        768  0,175     0,033     0,004     1,044     0,301        [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /home/murilo/report4.nsys-rep\n",
      "    /home/murilo/report4.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile --stats=true ./vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After profilling the application, answer the following questions using information displayed in the `CUDA Kernel Statistics` section of the profilling output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ NCU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NVIDIA Nsight Compute` (ncu) provides a non-interactive way to profile applications from the command line. It can print the results directly on the command line or store them in a report file. \n",
    "\n",
    "To print profilling information on the command line on the NCU, do not specify the output file (flag -o). Or, if you want to generate the output file (-o) and still see it on the command line, you can use the --page flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 36723 (/home/murilo/vector-add)\n",
      "==PROF== Profiling \"addVectorsInto\" - 0: 0%....50%....100% - 24 passes\n",
      "Success! All values calculated correctly.\n",
      "==PROF== Disconnected from process 36723\n",
      "[36723] vector-add@127.0.0.1\n",
      "  addVectorsInto(float *, float *, float *, int), 2025-Feb-19 18:56:49, Context 1, Stream 7\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    DRAM Frequency                                                           cycle/usecond                         852,16\n",
      "    SM Frequency                                                             cycle/nsecond                           1,26\n",
      "    Elapsed Cycles                                                                   cycle                        809.889\n",
      "    Memory [%]                                                                           %                          71,24\n",
      "    DRAM Throughput                                                                      %                          71,24\n",
      "    Duration                                                                       usecond                         643,52\n",
      "    L1/TEX Cache Throughput                                                              %                          19,43\n",
      "    L2 Cache Throughput                                                                  %                          25,45\n",
      "    SM Active Cycles                                                                 cycle                     817.904,80\n",
      "    Compute (SM) [%]                                                                     %                           5,11\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
      "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
      "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
      "          whether there are values you can (re)compute.                                                                 \n",
      "\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close \n",
      "          to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling    \n",
      "          Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on         \n",
      "          roofline analysis.                                                                                            \n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Executed Ipc Active                                                         inst/cycle                           0,19\n",
      "    Executed Ipc Elapsed                                                        inst/cycle                           0,19\n",
      "    Issue Slots Busy                                                                     %                           4,73\n",
      "    Issued Ipc Active                                                           inst/cycle                           0,19\n",
      "    SM Busy                                                                              %                           4,73\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Memory Throughput                                                         Gbyte/second                         621,62\n",
      "    Mem Busy                                                                             %                          25,45\n",
      "    Max Bandwidth                                                                        %                          71,24\n",
      "    L1/TEX Hit Rate                                                                      %                              0\n",
      "    L2 Hit Rate                                                                          %                          33,33\n",
      "    Mem Pipes Busy                                                                       %                           5,11\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    One or More Eligible                                                                 %                           4,77\n",
      "    Issued Warp Per Scheduler                                                                                        0,05\n",
      "    No Eligible                                                                          %                          95,23\n",
      "    Active Warps Per Scheduler                                                        warp                          15,07\n",
      "    Eligible Warps Per Scheduler                                                      warp                           0,12\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 21.0 cycles. This might leave hardware resources underutilized and may lead to    \n",
      "          less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of   \n",
      "          15.07 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps   \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, avoid possible load imbalances due to highly different execution durations per warp.          \n",
      "          Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.            \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Warp Cycles Per Issued Instruction                                               cycle                         316,03\n",
      "    Warp Cycles Per Executed Instruction                                             cycle                         316,57\n",
      "    Avg. Active Threads Per Warp                                                                                       32\n",
      "    Avg. Not Predicated Off Threads Per Warp                                                                        29,97\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   On average, each warp of this kernel spends 305.3 cycles being stalled waiting for a scoreboard dependency on \n",
      "          a L1TEX (local, global, surface, texture, rtcore) operation. This represents about 96.6% of the total         \n",
      "          average of 316.0 cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX     \n",
      "          data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase  \n",
      "          cache hit rates by increasing data locality or by changing the cache configuration, and consider moving       \n",
      "          frequently used data to registers and to shared memory.                                                       \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Source Counters section for the top stall locations in your source based on sampling data. The      \n",
      "          Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#sampling) provides   \n",
      "          more details on each stall reason.                                                                            \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Avg. Executed Instructions Per Scheduler                                          inst                         38.656\n",
      "    Executed Instructions                                                             inst                     12.369.920\n",
      "    Avg. Issued Instructions Per Scheduler                                            inst                      38.721,09\n",
      "    Issued Instructions                                                               inst                     12.390.749\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   This kernel executes 0 fused and 1048576 non-fused FP32 instructions. By converting pairs of non-fused        \n",
      "          instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point),           \n",
      "          higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its  \n",
      "          current performance). Check the Source page to identify where this kernel executes FP32 instructions.         \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Size                                                                                                      1.024\n",
      "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
      "    Grid Size                                                                                                       2.560\n",
      "    Registers Per Thread                                                   register/thread                             26\n",
      "    Shared Memory Configuration Size                                                  byte                              0\n",
      "    Driver Shared Memory Per Block                                              byte/block                              0\n",
      "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
      "    Static Shared Memory Per Block                                              byte/block                              0\n",
      "    Threads                                                                         thread                      2.621.440\n",
      "    Waves Per SM                                                                                                       16\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Limit SM                                                                   block                             32\n",
      "    Block Limit Registers                                                            block                              2\n",
      "    Block Limit Shared Mem                                                           block                             32\n",
      "    Block Limit Warps                                                                block                              2\n",
      "    Theoretical Active Warps per SM                                                   warp                             64\n",
      "    Theoretical Occupancy                                                                %                            100\n",
      "    Achieved Occupancy                                                                   %                          94,17\n",
      "    Achieved Active Warps Per SM                                                      warp                          60,27\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
      "\n",
      "    Section: Source Counters\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Branch Instructions Ratio                                                            %                           0,06\n",
      "    Branch Instructions                                                               inst                        720.896\n",
      "    Branch Efficiency                                                                    %                            100\n",
      "    Avg. Divergent Branches                                                                                             0\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ncu --set detailed vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Concurrent CUDA Streams`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CUDA programming, a **stream** is a series of commands that execute in order. In CUDA applications, kernel execution, as well as some memory transfers, occur within CUDA streams. Up until this point in time, you have not been interacting explicitly with CUDA streams, but in fact, your CUDA code has been executing its kernels inside of a stream called *the default stream*. CUDA programmers can create and utilize non-default CUDA streams in addition to the default stream, and in doing so, perform multiple operations, such as executing multiple kernels, concurrently, in different streams. Using multiple streams can add an additional layer of parallelization to your accelerated applications, and offers many more opportunities for application optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, Utilizing, and Destroying Non-Default CUDA Streams\n",
    "\n",
    "The following code snippet demonstrates how to create, utilize, and destroy a non-default CUDA stream. You will note, that to launch a CUDA kernel in a non-default CUDA stream, the stream must be passed as the optional 4th argument of the execution configuration. Up until now you have only utilized the first 2 arguments of the execution configuration:\n",
    "\n",
    "```cpp\n",
    "cudaStream_t stream;       // CUDA streams are of type `cudaStream_t`.\n",
    "cudaStreamCreate(&stream); // Note that a pointer must be passed to `cudaCreateStream`.\n",
    "\n",
    "someKernel<<<number_of_blocks, threads_per_block, 0, stream>>>(); // `stream` is passed as 4th EC argument.\n",
    "\n",
    "cudaStreamDestroy(stream); // Note that a value, not a pointer, is passed to `cudaDestroyStream`.\n",
    "```\n",
    "\n",
    "Outside the scope of this lab, but worth mentioning, is the optional 3rd argument of the execution configuration. This argument allows programmers to supply the number of bytes in **shared memory** (an advanced topic that will not be covered presently) to be dynamically allocated per block for this kernel launch. The default number of bytes allocated to shared memory per block is `0`, and for the remainder of the lab, you will be passing `0` as this value, in order to expose the 4th argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print-numbers-solution.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile print-numbers-solution.cu\n",
    "#include <stdio.h>\n",
    "#include <unistd.h>\n",
    "\n",
    "__global__ void printNumber(int number)\n",
    "{\n",
    "  printf(\"%d\\n\", number);\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int i;\n",
    "    \n",
    "  for(i = 0; i < 5; ++i)\n",
    "  {\n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    printNumber<<<1, 1, 0, stream>>>(i);\n",
    "    cudaStreamDestroy(stream);\n",
    "  }\n",
    "    \n",
    "  cudaDeviceSynchronize();\n",
    "    \n",
    "  return 0;  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc print-numbers-solution.cu -o print-numbers-solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "!./print-numbers-solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Asynchronous Memory Prefetching`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefetching also tends to migrate data in larger chunks, and therefore fewer trips, than on-demand migration. This makes it an excellent fit when data access needs are known before runtime, and when data access patterns are not sparse.\n",
    "\n",
    "CUDA Makes asynchronously prefetching managed memory to either a GPU device or the CPU easy with its `cudaMemPrefetchAsync` function. Here is an example of using it to both prefetch data to the currently active GPU device, and then, to the CPU:\n",
    "\n",
    "```cpp\n",
    "\n",
    "int deviceId;\n",
    "cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n",
    "\n",
    "cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n",
    "cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n",
    "                                                                  // built-in CUDA variable.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vector-add-prefetching.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector-add-prefetching.cu\n",
    "#include <stdio.h>\n",
    "#define N 2048 * 2048 // Number of elements in each vector\n",
    "\n",
    "__global__ void saxpy(int * a, int * b, int * c)\n",
    "{\n",
    "  // Determine our unique global thread ID, so we know which element to process\n",
    "  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  \n",
    "  for (int i = tid; i < N; i += stride)\n",
    "     c[i] = 2 * a[i] + b[i];\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int *a, *b, *c;\n",
    "\n",
    "  int size = N * sizeof (int); // The total number of bytes per vector\n",
    "\n",
    "  int deviceId;\n",
    "  int numberOfSMs;\n",
    "\n",
    "  cudaGetDevice(&deviceId);\n",
    "  cudaDeviceGetAttribute(&numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);\n",
    "\n",
    "  // Allocate memory\n",
    "  cudaMallocManaged(&a, size);\n",
    "  cudaMallocManaged(&b, size);\n",
    "  cudaMallocManaged(&c, size);\n",
    "\n",
    "  // Initialize memory\n",
    "  for(int i = 0; i < N; ++i )\n",
    "  {\n",
    "    a[i] = 2;\n",
    "    b[i] = 1;\n",
    "    c[i] = 0;\n",
    "  }\n",
    "\n",
    "  cudaMemPrefetchAsync(a, size, deviceId);\n",
    "  cudaMemPrefetchAsync(b, size, deviceId);\n",
    "  cudaMemPrefetchAsync(c, size, deviceId);\n",
    "\n",
    "  int threads_per_block = 256;\n",
    "  int number_of_blocks = numberOfSMs * 32;\n",
    "\n",
    "  saxpy <<<number_of_blocks, threads_per_block>>>( a, b, c );\n",
    "\n",
    "  cudaDeviceSynchronize(); // Wait for the GPU to finish\n",
    "\n",
    "  // Print out the first and last 5 values of c for a quality check\n",
    "  for( int i = 0; i < 5; ++i )\n",
    "    printf(\"c[%d] = %d, \", i, c[i]);\n",
    "  printf (\"\\n\");\n",
    "  for( int i = N-5; i < N; ++i )\n",
    "    printf(\"c[%d] = %d, \", i, c[i]);\n",
    "  printf (\"\\n\");\n",
    "\n",
    "  // Free all our allocated memory\n",
    "  cudaFree(a); \n",
    "  cudaFree(b); \n",
    "  cudaFree(c);\n",
    "    \n",
    "  return 0;  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vector-add-prefetching.cu -o vector-add-prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n",
      "c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n"
     ]
    }
   ],
   "source": [
    "!./vector-add-prefetching"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1MCx31lj9AcWrqGReFyiNTFoHwErZ2iC5",
     "timestamp": 1739366102672
    },
    {
     "file_id": "1iD5CokXvx02AYYVFCBCpmeNRvtmMgIvJ",
     "timestamp": 1705313939307
    },
    {
     "file_id": "1ZkyYkRzX6g3uldQhU-bgMF5jzn1k3C7J",
     "timestamp": 1705310081089
    },
    {
     "file_id": "19ofstzfOeJlZYKFSrJk6seqe2oJWv1xS",
     "timestamp": 1698257221671
    },
    {
     "file_id": "1OhujvtZ8HLCXG4JU56I72vBJlfqYb9Kk",
     "timestamp": 1694022921959
    },
    {
     "file_id": "1e_lXiysoxz98IAygtljP-0xTOO6FaYV4",
     "timestamp": 1692812241795
    },
    {
     "file_id": "https://github.com/muriloboratto/programacao-jogos-digitais/blob/master/JD0007/notebooks/01-Entradas-Saidas.ipynb",
     "timestamp": 1678191303998
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
